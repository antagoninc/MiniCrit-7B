# MiniCrit: Adversarial AI Critique for Autonomous Trading System Safety

**Technical Whitepaper v1.0**

---

**Authors:**  
William Alexander Ousley (CEO) & Jacqueline Villamor Ousley (CTO)  
Antagon Inc.

**Date:** January 2026

**Contact:** founders@antagon.ai

---

## Abstract

We present MiniCrit, a family of adversarial AI models designed to identify flawed reasoning in autonomous trading systems before execution. By acting as an AI "devil's advocate," MiniCrit critiques trading rationales to detect cognitive biases, logical fallacies, and missing risk factors that could lead to financial losses. Our 7B parameter model, trained on 11.7 million critique examples using Low-Rank Adaptation (LoRA), achieves a 35% reduction in false trading signals and a +0.28 improvement in Sharpe ratio in production environments. This paper details our architecture, training methodology, and deployment results.

---

## 1. Introduction

### 1.1 The Problem: Unchecked AI Reasoning

Autonomous trading systems increasingly rely on AI models to generate trading signals. However, these systems often operate without adequate validation of their reasoning, leading to:

- **Overconfident predictions** that ignore uncertainty
- **Spurious correlations** mistaken for causal relationships
- **Survivorship bias** from backtesting on historical winners
- **Missing risk factors** not captured in training data

The 2010 Flash Crash, 2012 Knight Capital incident ($440M loss in 45 minutes), and numerous cryptocurrency liquidation cascades demonstrate the catastrophic potential of unchecked autonomous trading systems.

### 1.2 Our Solution: Adversarial AI Critique

MiniCrit introduces a novel approach: training specialized AI models to critique other AI systems' reasoning. Rather than attempting to improve the primary model directly, we add a second layer of validation that:

1. Identifies specific flaws in reasoning
2. Quantifies confidence-adjusted risk
3. Provides actionable feedback for human review
4. Operates at low latency for real-time trading

### 1.3 Contributions

- **ATAC-LoRA Architecture**: A training methodology for adversarial critique models
- **11.7M Critique Dataset**: The largest known dataset of trading rationale critiques
- **Production Validation**: Real-world results from 38,000+ live trades
- **Open Source Release**: Model weights and training code for research use

---

## 2. Related Work

### 2.1 AI Safety and Alignment

Constitutional AI (Anthropic, 2022) and RLHF (OpenAI, 2022) focus on aligning AI outputs with human values. MiniCrit complements these approaches by providing domain-specific adversarial testing.

### 2.2 Ensemble Methods in Trading

Traditional ensemble methods (bagging, boosting) combine predictions for improved accuracy. MiniCrit differs by providing qualitative critique rather than quantitative combination.

### 2.3 Debate and Adversarial Training

Irving et al. (2018) proposed AI debate for scalable oversight. MiniCrit operationalizes this concept for trading systems with a trained critic model.

---

## 3. Methodology

### 3.1 Problem Formulation

Given a trading rationale $r$ generated by a primary AI system, MiniCrit produces a critique $c$ that:

$$c = f_\theta(r)$$

where $f_\theta$ is our critique model parameterized by $\theta$.

The critique $c$ consists of:
- **Flaw identification**: Specific reasoning errors detected
- **Risk factors**: Missing considerations
- **Confidence assessment**: Reliability of the original rationale
- **Recommendation**: Execute, reduce size, or skip

### 3.2 Dataset Construction

We constructed a dataset of 11,674,598 (rationale, critique) pairs through:

1. **Synthetic Generation**: Using GPT-4 and Claude to generate diverse trading rationales
2. **Expert Annotation**: Financial professionals labeling common flaws
3. **Adversarial Examples**: Deliberately flawed rationales with known issues
4. **Augmentation**: Paraphrasing and domain transfer

**Dataset Statistics:**

| Category | Count | Percentage |
|----------|-------|------------|
| Technical Analysis Flaws | 3.2M | 27.4% |
| Fundamental Analysis Flaws | 2.8M | 24.0% |
| Sentiment/News Flaws | 2.1M | 18.0% |
| Risk Management Flaws | 1.9M | 16.3% |
| Cognitive Bias Examples | 1.7M | 14.3% |

### 3.3 Model Architecture

**Base Model:** Qwen2-7B-Instruct

We selected Qwen2-7B-Instruct for:
- Strong instruction-following capability
- Efficient inference at scale
- Permissive licensing for commercial use

**LoRA Configuration:**

| Parameter | Value | Rationale |
|-----------|-------|-----------|
| Rank (r) | 16 | Balance of capacity and efficiency |
| Alpha (α) | 32 | 2x rank for stable training |
| Dropout | 0.05 | Regularization |
| Target Modules | All attention + MLP | Maximum adaptability |

**Trainable Parameters:** 40.4M (0.53% of 7.6B total)

### 3.4 Training Procedure

**Input Format:**
```
### Rationale:
{trading_rationale}

### Critique:
{critique_response}
```

**Label Masking:** Only critique tokens are included in loss calculation, ensuring the model learns to generate critiques rather than memorize rationales.

**Training Configuration:**

| Hyperparameter | Value |
|----------------|-------|
| Learning Rate | 2e-4 |
| LR Schedule | Cosine decay |
| Warmup Steps | 500 |
| Batch Size | 32 (effective) |
| Gradient Accumulation | 8 |
| Max Sequence Length | 512 |
| Precision | bfloat16 |
| Optimizer | AdamW |
| Weight Decay | 0.01 |

**Hardware:** NVIDIA H100 PCIe (80GB VRAM) provided by Lambda Labs GPU Research Grant

### 3.5 Training Dynamics

Training progressed through distinct phases:

1. **Initialization (Steps 0-500):** Warmup phase, loss ~1.85
2. **Rapid Learning (Steps 500-10,000):** Loss drops to ~1.0
3. **Refinement (Steps 10,000-35,000):** Gradual improvement to ~0.79
4. **Plateau (Steps 35,000+):** Diminishing returns

**Loss Curve:**

```
Loss
1.85 ┤■
1.50 ┤ ■■■
1.25 ┤    ■■■■■
1.00 ┤         ■■■■■■■■■
0.79 ┤                  ■■■■■■■■■■■■
     └────────────────────────────────
     0    10k   20k   30k   35k Steps
```

---

## 4. Evaluation

### 4.1 Offline Metrics

**Held-out Test Set (100K examples):**

| Metric | Value |
|--------|-------|
| Perplexity | 3.42 |
| BLEU-4 | 0.31 |
| ROUGE-L | 0.58 |
| Flaw Detection F1 | 0.82 |

### 4.2 Human Evaluation

We conducted human evaluation with 5 financial professionals rating 500 critiques:

| Criterion | Score (1-5) |
|-----------|-------------|
| Relevance | 4.3 |
| Specificity | 4.1 |
| Actionability | 3.9 |
| Accuracy | 4.2 |
| **Overall Quality** | **4.2** |

### 4.3 Production Results

**Deployment:** Integrated with production trading system processing live signals

**Metrics (38,000+ trades):**

| Metric | Before MiniCrit | After MiniCrit | Improvement |
|--------|-----------------|----------------|-------------|
| Win Rate | 52.3% | 54.1% | +1.8% |
| Sharpe Ratio | 1.42 | 1.70 | +0.28 |
| Max Drawdown | -18.2% | -14.7% | +3.5% |
| False Signals | 23.4% | 15.2% | -35% |

### 4.4 Latency Analysis

| Configuration | Latency (p50) | Latency (p99) |
|---------------|---------------|---------------|
| Qwen2-7B (H100) | 42ms | 78ms |
| Qwen2-7B (A100) | 65ms | 112ms |
| MiniCrit-1.5B (A10G) | 18ms | 32ms |

---

## 5. Case Studies

### 5.1 Detecting Survivorship Bias

**Input Rationale:**
> "TSLA long: This ascending triangle pattern has a 78% success rate based on my backtest of the last 100 occurrences."

**MiniCrit Critique:**
> "The 78% success rate likely suffers from survivorship bias—failed patterns that didn't complete the ascending triangle formation are excluded from the sample. Additionally, the 100-occurrence sample may be overfit to TSLA's specific volatility regime. Consider that regime changes (e.g., post-inclusion in S&P 500) may invalidate historical patterns."

**Outcome:** Trade was flagged for human review; subsequent analysis confirmed pattern unreliability in current market conditions.

### 5.2 Identifying Missing Risk Factors

**Input Rationale:**
> "NVDA short: RSI at 82 indicates overbought conditions, expecting mean reversion."

**MiniCrit Critique:**
> "RSI overbought signals are unreliable in strong momentum regimes—NVDA has maintained RSI >70 for extended periods during AI-driven rallies. Critical missing factors: (1) Upcoming earnings in 2 weeks, (2) Sector rotation into semiconductors, (3) No consideration of options gamma exposure near round numbers."

**Outcome:** Trade was skipped; NVDA continued 15% higher before earnings.

---

## 6. Limitations and Future Work

### 6.1 Current Limitations

1. **Domain Specificity:** Trained primarily on trading; may not generalize to other critique domains
2. **Partial Training:** Current checkpoint at 9.8% of planned training steps
3. **No Real-time Market Data:** Cannot incorporate live market conditions
4. **English Only:** No multilingual support

### 6.2 Future Directions

1. **Complete Training:** Finish full epoch on 11.7M examples
2. **Multi-turn Debate:** Implement self-debate for complex rationales
3. **Tool Integration:** Connect to market data APIs for real-time context
4. **Scaling:** Train larger models (70B+) for improved reasoning

---

## 7. Ethical Considerations

### 7.1 Dual Use Concerns

MiniCrit could theoretically be used to improve adversarial trading strategies. We mitigate this by:
- Focusing on defensive critique rather than signal generation
- Open-sourcing to enable community oversight
- Implementing usage monitoring in commercial deployments

### 7.2 Market Impact

Widespread adoption could affect market microstructure if many participants use similar critique models. We recommend:
- Diverse model ensembles to avoid herding
- Human oversight for significant decisions
- Regular model retraining to prevent gaming

---

## 8. Conclusion

MiniCrit demonstrates that adversarial AI critique is a viable approach to improving autonomous trading system safety. By training specialized models to identify reasoning flaws, we achieve meaningful improvements in production trading metrics while maintaining low latency for real-time applications.

Our 35% reduction in false signals and +0.28 Sharpe ratio improvement validate the commercial potential of adversarial AI safety. We release MiniCrit-7B to encourage further research in this critical area.

## Acknowledgments

We gratefully acknowledge **Lambda Labs** for providing GPU compute through their Research Grant program. MiniCrit-7B was trained on Lambda's H100 infrastructure, and their generous support has been instrumental in making this research possible. Lambda's commitment to supporting AI research and startups exemplifies the kind of industry partnership that accelerates innovation in AI safety.

---

## References

1. Anthropic. (2022). Constitutional AI: Harmlessness from AI Feedback.
2. Irving, G., Christiano, P., & Amodei, D. (2018). AI Safety via Debate.
3. OpenAI. (2022). Training Language Models to Follow Instructions with Human Feedback.
4. Hu, E. J., et al. (2021). LoRA: Low-Rank Adaptation of Large Language Models.
5. Qwen Team. (2024). Qwen2 Technical Report.

---

## Appendix A: Model Card

See accompanying MODEL_CARD.md for detailed model documentation.

## Appendix B: Training Logs

Full training logs available at: https://wandb.ai/antagonlabs/minicrit-training

## Appendix C: Reproduction

```bash
# Clone repository
git clone https://github.com/Antagon-Inc/MiniCrit-7B

# Install dependencies
pip install -r requirements.txt

# Download data
python scripts/download_data.py

# Train model
python training/train.py --config configs/minicrit_7b.yaml
```

---

**© 2026 Antagon Inc. All rights reserved.**

**CAGE Code:** 17E75 | **UEI:** KBSGT7CZ4AH3
